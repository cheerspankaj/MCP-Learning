{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: Introduction to OpenAI API & Prompting\n",
    "\n",
    "This module introduces participants to the motivation for working with the OpenAI API and the fundamentals for doing so. Participants will learn about the OpenAI Platform, types of prompting, and be introduced to advanced topics covered in later modules (e.g. RAG, Agents)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT -> API \n",
    "Let's begin by exploring how we could use ChatGPT for a data validation task and compare the responses from different models.\n",
    "\n",
    "Below we have some sample data for concommitant medications and medical history events. Let's ask two different models in ChatGPT to identify medications that do not have an associated condition (a likely data quality issue). The optimal answer is that the model identifies that Advil (Patient 1) and Creatine (Patient 3) have no associated patient condition.\n",
    "\n",
    "We'll start using by passing the following prompt to 4o-mini and to o1 mini:\n",
    "```\n",
    "# Task\n",
    "Go through the following medication and condition lists and return medications for which the patient does not have an associated condition.\n",
    "\n",
    "# Input\n",
    "\n",
    "## Medications:\n",
    "[\n",
    "    (\"Patient 1\", \"Metformin\"),\n",
    "    (\"Patient 1\", \"Advil\"),\n",
    "    (\"Patient 2\", \"Humira\"),\n",
    "    (\"Patient 3\", \"Dupixent\"),\n",
    "    (\"Patient 3\", \"Creatine\"),\n",
    "]\n",
    "\n",
    "## Conditions:\n",
    "[\n",
    "    (\"Patient 1\", \"Diabetes\"),\n",
    "    (\"Patient 1\", \"Chronic Asthma\"),\n",
    "    (\"Patient 2\", \"Rheumatoid Arthritis\"),\n",
    "    (\"Patient 3\", \"Eczema\"),\n",
    "]\n",
    "```\n",
    "Screenshots of responses:\n",
    "- 4o mini: https://chatgpt.com/share/e/67d3152b-028c-8005-a131-e31a60dc07d0\n",
    "- o3-mini: https://chatgpt.com/share/e/67d314f1-9020-8005-bce1-94909e307bc8\n",
    "- o3-mini-high: https://chatgpt.com/share/e/67d31566-486c-8005-8269-ac25065cd7af\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to OpenAI API\n",
    "\n",
    "In the above example, it would become tedious to continually update this prompt and paste it into ChatGPT (e.g. for patients at multiple trial sites or at various points in the trial) or to use a larger dataset. It would be easier and more scalable to use the OpenAI API to automate this process. \n",
    "\n",
    "### API Advantages\n",
    "- Automated Programmatic Workflows\n",
    "   - Enables automation of repetitive tasks, allowing you to run the same processes multiple times with different inputs efficiently (as well as batch processing!)\n",
    "- Enhanced Control Over Model Configuration\n",
    "   - Greater flexibility in choosing specific models, adjusting model parameters, and customizing system prompts\n",
    "- Production-Ready Capabilities\n",
    "   - Facilitates embedding AI capabilities directly into applications that can scale and handle large volumes of requests\n",
    "   - Developers can select and lock specific model versions and integrate with monitoring tools to track usage, performance, and error rates\n",
    "\n",
    "### API Keys\n",
    "OpenAI API keys are used to securely access the API and should be set as an environment variable when interacting with the OpenAI models.\n",
    "\n",
    "To see your individual API key(s) go to https://platform.openai.com/settings/project/api-keys. Here you can also create new API keys if you want to separately track your usage for various projects/use cases.\n",
    "\n",
    "At Genmab we use \"Project Keys\" for personal development and non-production use cases. If your use case evolves and needs a Service Key, submit a consultation request via [this link](https://teams.microsoft.com/l/entity/81fef3a6-72aa-4648-a763-de824aeafb7d/_djb2_msteams_prefix_1776558767?context=%7B%22channelId%22%3A%2219%3Af44efea3d91e4a1c9da746d204a90ff3%40thread.tacv2%22%7D&tenantId=9a88a419-24b9-401f-8557-e155db7ae966) and Farhat will get back to you. Service accounts are tied to a \"bot\" individual and should be used to provision access for production systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3==1.35.76 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from -r requirements1.txt (line 1)) (1.35.76)\n",
      "Requirement already satisfied: datasets==3.2.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from -r requirements1.txt (line 2)) (3.2.0)\n",
      "Requirement already satisfied: dspy==2.5.43 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from -r requirements1.txt (line 3)) (2.5.43)\n",
      "Requirement already satisfied: ipykernel>=6.29.5 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from -r requirements1.txt (line 4)) (6.29.5)\n",
      "Requirement already satisfied: jupyter>=1.1.1 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from -r requirements1.txt (line 5)) (1.1.1)\n",
      "Requirement already satisfied: langchain==0.3.17 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from -r requirements1.txt (line 6)) (0.3.17)\n",
      "Requirement already satisfied: langchain-community==0.3.16 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from -r requirements1.txt (line 7)) (0.3.16)\n",
      "Requirement already satisfied: langchain-openai==0.3.3 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from -r requirements1.txt (line 8)) (0.3.3)\n",
      "Requirement already satisfied: nltk==3.9.1 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from -r requirements1.txt (line 9)) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.66.3 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from -r requirements1.txt (line 10)) (1.66.5)\n",
      "Requirement already satisfied: pandas>=2.2.3 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from -r requirements1.txt (line 11)) (2.2.3)\n",
      "Requirement already satisfied: pydantic>=2.10.3 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from -r requirements1.txt (line 12)) (2.10.6)\n",
      "Requirement already satisfied: rouge-score==0.1.2 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from -r requirements1.txt (line 13)) (0.1.2)\n",
      "Requirement already satisfied: streamlit==1.41.1 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from -r requirements1.txt (line 14)) (1.41.1)\n",
      "Requirement already satisfied: transformers>=4.47.1 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from -r requirements1.txt (line 15)) (4.49.0)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.76 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from boto3==1.35.76->-r requirements1.txt (line 1)) (1.35.99)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from boto3==1.35.76->-r requirements1.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from boto3==1.35.76->-r requirements1.txt (line 1)) (0.10.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets==3.2.0->-r requirements1.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets==3.2.0->-r requirements1.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets==3.2.0->-r requirements1.txt (line 2)) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets==3.2.0->-r requirements1.txt (line 2)) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets==3.2.0->-r requirements1.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets==3.2.0->-r requirements1.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets==3.2.0->-r requirements1.txt (line 2)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets==3.2.0->-r requirements1.txt (line 2)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.2.0->-r requirements1.txt (line 2)) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets==3.2.0->-r requirements1.txt (line 2)) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets==3.2.0->-r requirements1.txt (line 2)) (0.29.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets==3.2.0->-r requirements1.txt (line 2)) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets==3.2.0->-r requirements1.txt (line 2)) (6.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from dspy==2.5.43->-r requirements1.txt (line 3)) (4.2.0)\n",
      "Requirement already satisfied: asyncer==0.0.8 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from dspy==2.5.43->-r requirements1.txt (line 3)) (0.0.8)\n",
      "Requirement already satisfied: backoff in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from dspy==2.5.43->-r requirements1.txt (line 3)) (2.2.1)\n",
      "Requirement already satisfied: cachetools in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from dspy==2.5.43->-r requirements1.txt (line 3)) (4.2.2)\n",
      "Requirement already satisfied: diskcache in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from dspy==2.5.43->-r requirements1.txt (line 3)) (5.6.3)\n",
      "Requirement already satisfied: httpx in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from dspy==2.5.43->-r requirements1.txt (line 3)) (0.27.2)\n",
      "Requirement already satisfied: joblib~=1.3 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from dspy==2.5.43->-r requirements1.txt (line 3)) (1.4.2)\n",
      "Requirement already satisfied: json-repair in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from dspy==2.5.43->-r requirements1.txt (line 3)) (0.40.0)\n",
      "Requirement already satisfied: litellm==1.53.7 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (1.53.7)\n",
      "Requirement already satisfied: magicattr~=0.1.6 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from dspy==2.5.43->-r requirements1.txt (line 3)) (0.1.6)\n",
      "Requirement already satisfied: optuna in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from dspy==2.5.43->-r requirements1.txt (line 3)) (4.2.1)\n",
      "Requirement already satisfied: regex in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from dspy==2.5.43->-r requirements1.txt (line 3)) (2023.10.3)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from dspy==2.5.43->-r requirements1.txt (line 3)) (9.0.0)\n",
      "Requirement already satisfied: ujson in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from dspy==2.5.43->-r requirements1.txt (line 3)) (5.4.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from dspy==2.5.43->-r requirements1.txt (line 3)) (2.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from dspy==2.5.43->-r requirements1.txt (line 3)) (3.1.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain==0.3.17->-r requirements1.txt (line 6)) (2.0.25)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain==0.3.17->-r requirements1.txt (line 6)) (0.3.45)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain==0.3.17->-r requirements1.txt (line 6)) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain==0.3.17->-r requirements1.txt (line 6)) (0.3.17)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-community==0.3.16->-r requirements1.txt (line 7)) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-community==0.3.16->-r requirements1.txt (line 7)) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-community==0.3.16->-r requirements1.txt (line 7)) (2.8.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-openai==0.3.3->-r requirements1.txt (line 8)) (0.9.0)\n",
      "Requirement already satisfied: click in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk==3.9.1->-r requirements1.txt (line 9)) (8.1.7)\n",
      "Requirement already satisfied: absl-py in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from rouge-score==0.1.2->-r requirements1.txt (line 13)) (2.1.0)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from rouge-score==0.1.2->-r requirements1.txt (line 13)) (1.16.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements1.txt (line 14)) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements1.txt (line 14)) (1.6.2)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements1.txt (line 14)) (10.2.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements1.txt (line 14)) (3.20.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements1.txt (line 14)) (13.9.4)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements1.txt (line 14)) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements1.txt (line 14)) (4.12.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements1.txt (line 14)) (2.1.6)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements1.txt (line 14)) (3.1.37)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements1.txt (line 14)) (0.8.0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements1.txt (line 14)) (6.3.3)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from litellm==1.53.7->litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (7.0.1)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from litellm==1.53.7->litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (4.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from litellm==1.53.7->litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (0.21.0)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from litellm==1.53.7->litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (0.21.1)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.8.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (2.10.1)\n",
      "Requirement already satisfied: apscheduler<4.0.0,>=3.10.4 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (3.11.0)\n",
      "Requirement already satisfied: cryptography<43.0.0,>=42.0.5 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (42.0.8)\n",
      "Requirement already satisfied: fastapi<0.112.0,>=0.111.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (0.111.1)\n",
      "Requirement already satisfied: fastapi-sso<0.11.0,>=0.10.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (0.10.0)\n",
      "Requirement already satisfied: gunicorn<23.0.0,>=22.0.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (22.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.7 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (3.10.15)\n",
      "Requirement already satisfied: pynacl<2.0.0,>=1.5.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (1.5.0)\n",
      "Requirement already satisfied: python-multipart<0.0.10,>=0.0.9 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (0.0.9)\n",
      "Requirement already satisfied: rq in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: uvicorn<0.23.0,>=0.22.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (0.22.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from ipykernel>=6.29.5->-r requirements1.txt (line 4)) (0.1.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from ipykernel>=6.29.5->-r requirements1.txt (line 4)) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from ipykernel>=6.29.5->-r requirements1.txt (line 4)) (8.20.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from ipykernel>=6.29.5->-r requirements1.txt (line 4)) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from ipykernel>=6.29.5->-r requirements1.txt (line 4)) (5.5.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from ipykernel>=6.29.5->-r requirements1.txt (line 4)) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from ipykernel>=6.29.5->-r requirements1.txt (line 4)) (1.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from ipykernel>=6.29.5->-r requirements1.txt (line 4)) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from ipykernel>=6.29.5->-r requirements1.txt (line 4)) (25.1.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from ipykernel>=6.29.5->-r requirements1.txt (line 4)) (5.7.1)\n",
      "Requirement already satisfied: notebook in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyter>=1.1.1->-r requirements1.txt (line 5)) (7.0.8)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyter>=1.1.1->-r requirements1.txt (line 5)) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyter>=1.1.1->-r requirements1.txt (line 5)) (7.10.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyter>=1.1.1->-r requirements1.txt (line 5)) (7.6.5)\n",
      "Requirement already satisfied: jupyterlab in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyter>=1.1.1->-r requirements1.txt (line 5)) (4.0.11)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from openai>=1.66.3->-r requirements1.txt (line 10)) (1.8.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from openai>=1.66.3->-r requirements1.txt (line 10)) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from openai>=1.66.3->-r requirements1.txt (line 10)) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas>=2.2.3->-r requirements1.txt (line 11)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas>=2.2.3->-r requirements1.txt (line 11)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas>=2.2.3->-r requirements1.txt (line 11)) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic>=2.10.3->-r requirements1.txt (line 12)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic>=2.10.3->-r requirements1.txt (line 12)) (2.27.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers>=4.47.1->-r requirements1.txt (line 15)) (0.5.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->datasets==3.2.0->-r requirements1.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->datasets==3.2.0->-r requirements1.txt (line 2)) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->datasets==3.2.0->-r requirements1.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->datasets==3.2.0->-r requirements1.txt (line 2)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->datasets==3.2.0->-r requirements1.txt (line 2)) (1.9.3)\n",
      "Requirement already satisfied: toolz in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.41.1->-r requirements1.txt (line 14)) (0.12.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from anyio->dspy==2.5.43->-r requirements1.txt (line 3)) (3.4)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from botocore<1.36.0,>=1.35.76->boto3==1.35.76->-r requirements1.txt (line 1)) (2.0.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from click->nltk==3.9.1->-r requirements1.txt (line 9)) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.16->-r requirements1.txt (line 7)) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.16->-r requirements1.txt (line 7)) (0.9.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.41.1->-r requirements1.txt (line 14)) (4.0.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx->dspy==2.5.43->-r requirements1.txt (line 3)) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx->dspy==2.5.43->-r requirements1.txt (line 3)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->dspy==2.5.43->-r requirements1.txt (line 3)) (0.14.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.29.5->-r requirements1.txt (line 4)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.29.5->-r requirements1.txt (line 4)) (0.18.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.29.5->-r requirements1.txt (line 4)) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.29.5->-r requirements1.txt (line 4)) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.29.5->-r requirements1.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2->dspy==2.5.43->-r requirements1.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=6.29.5->-r requirements1.txt (line 4)) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=6.29.5->-r requirements1.txt (line 4)) (305.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain==0.3.17->-r requirements1.txt (line 6)) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.17->-r requirements1.txt (line 6)) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.17->-r requirements1.txt (line 6)) (0.23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets==3.2.0->-r requirements1.txt (line 2)) (2.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit==1.41.1->-r requirements1.txt (line 14)) (2.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.17->-r requirements1.txt (line 6)) (3.0.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter>=1.1.1->-r requirements1.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter>=1.1.1->-r requirements1.txt (line 5)) (5.9.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter>=1.1.1->-r requirements1.txt (line 5)) (3.5.2)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter>=1.1.1->-r requirements1.txt (line 5)) (3.0.9)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (2.0.4)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (2.2.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (2.10.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.19.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (2.25.1)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (0.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from nbconvert->jupyter>=1.1.1->-r requirements1.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from nbconvert->jupyter>=1.1.1->-r requirements1.txt (line 5)) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from nbconvert->jupyter>=1.1.1->-r requirements1.txt (line 5)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from nbconvert->jupyter>=1.1.1->-r requirements1.txt (line 5)) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from nbconvert->jupyter>=1.1.1->-r requirements1.txt (line 5)) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from nbconvert->jupyter>=1.1.1->-r requirements1.txt (line 5)) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from nbconvert->jupyter>=1.1.1->-r requirements1.txt (line 5)) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from nbconvert->jupyter>=1.1.1->-r requirements1.txt (line 5)) (1.2.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from optuna->dspy==2.5.43->-r requirements1.txt (line 3)) (1.15.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from optuna->dspy==2.5.43->-r requirements1.txt (line 3)) (6.9.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna->dspy==2.5.43->-r requirements1.txt (line 3)) (1.3.9)\n",
      "Requirement already satisfied: tzlocal>=3.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from apscheduler<4.0.0,>=3.10.4->litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (5.3.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from bleach!=5.0.0->nbconvert->jupyter>=1.1.1->-r requirements1.txt (line 5)) (0.5.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from cryptography<43.0.0,>=42.0.5->litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from fastapi<0.112.0,>=0.111.0->litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from fastapi<0.112.0,>=0.111.0->litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (0.0.7)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from fastapi<0.112.0,>=0.111.0->litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (2.2.0)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from fastapi-sso<0.11.0,>=0.10.0->litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (3.2.2)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.41.1->-r requirements1.txt (line 14)) (4.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from importlib-metadata>=6.8.0->litellm==1.53.7->litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (3.17.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.29.5->-r requirements1.txt (line 4)) (0.8.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain==0.3.17->-r requirements1.txt (line 6)) (2.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.53.7->litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.53.7->litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.53.7->litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (0.10.6)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (21.3.0)\n",
      "Requirement already satisfied: jupyter-events>=0.6.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (0.8.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (0.4.4)\n",
      "Requirement already satisfied: overrides in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (0.14.1)\n",
      "Requirement already satisfied: pywinpty in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (2.0.10)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (0.17.1)\n",
      "Requirement already satisfied: websocket-client in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (0.58.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (2.11.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (0.9.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit==1.41.1->-r requirements1.txt (line 14)) (0.1.0)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->jupyter>=1.1.1->-r requirements1.txt (line 5)) (2.16.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel>=6.29.5->-r requirements1.txt (line 4)) (0.2.5)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.16->-r requirements1.txt (line 7)) (1.0.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter>=1.1.1->-r requirements1.txt (line 5)) (2.5)\n",
      "Requirement already satisfied: redis>=3.5 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from rq->litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (5.2.1)\n",
      "Requirement already satisfied: executing in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.29.5->-r requirements1.txt (line 4)) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.29.5->-r requirements1.txt (line 4)) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.29.5->-r requirements1.txt (line 4)) (0.2.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography<43.0.0,>=42.0.5->litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (2.21)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from email_validator>=2.0.0->fastapi<0.112.0,>=0.111.0->litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (2.7.0)\n",
      "Requirement already satisfied: typer>=0.12.3 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from fastapi-cli>=0.0.2->fastapi<0.112.0,>=0.111.0->litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (0.15.2)\n",
      "Requirement already satisfied: rich-toolkit>=0.11.1 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from fastapi-cli>=0.0.2->fastapi<0.112.0,>=0.111.0->litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (0.13.2)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (0.1.1)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi<0.112.0,>=0.111.0->litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi<0.112.0,>=0.111.0->litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi<0.112.0,>=0.111.0->litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (15.0.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (21.2.0)\n",
      "Requirement already satisfied: fqdn in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (20.11.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (24.11.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<0.112.0,>=0.111.0->litellm[proxy]==1.53.7->dspy==2.5.43->-r requirements1.txt (line 3)) (1.5.4)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\paks\\appdata\\local\\anaconda3\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.1.1->-r requirements1.txt (line 5)) (1.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import openai\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the key for the AI Course below\n",
    " \n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your_api_key_here\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Completions API\n",
    "\n",
    "OpenAI provides simple APIs to use an LLM to generate text from a prompt, as you might using ChatGPT. The [Chat Completions API](https://platform.openai.com/docs/api-reference/chat) is a powerful tool for building conversational agents and dynamic responses. We can use it to create dialogues, making it essential for various applications like customer service bots, virtual assistants, and more. \n",
    "\n",
    "The format of the Chat Completitions API is common and highly useful for building agents (which we'll see in a later session). The structure of multiple messages, each with a role (user, system, assistant) and content helps maintain a clear context for interactions, which is essential when building multi-turn dialogues.\n",
    "\n",
    "Each chat completitions request must specify a minimum of two parameters:\n",
    "1. `model`: the model ID to use\n",
    "2. `messages`: a list of dictionaries where each dictionary represents a message in the conversation. Each message must have:\n",
    "   - `role`: such as [`system`](https://platform.openai.com/docs/guides/text-generation#system-messages), [`user`](https://platform.openai.com/docs/guides/text-generation#user-messages), or [`assistant`](https://platform.openai.com/docs/guides/text-generation#assistant-messages)\n",
    "   - `content`: which is the main body of the message that conveys information or questions\n",
    "\n",
    "\n",
    "To get a better feel for the Chat Completions API lets try to recreate a chatbot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='The capital of France is Paris.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "]\n",
    "\n",
    "# See possible models here: https://platform.openai.com/docs/models#model-endpoint-compatibility\n",
    "client = openai.OpenAI()\n",
    "response = client.chat.completions.create(\n",
    "        model= \"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "# Structure of response from model described here: https://platform.openai.com/docs/api-reference/chat/object\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last update in 2023, the population of Paris is approximately 2.1 million residents within the city limits. However, the larger metropolitan area, known as the le-de-France region, has a population of around 12 million people. For the most current population figures, its always a good idea to consult the latest census data or official statistics.\n"
     ]
    }
   ],
   "source": [
    "# Lets add this message to our dialogue and ask a follow up question\n",
    "messages.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
    "messages.append({\"role\": \"user\", \"content\": \"And what is the population of that city?\"})\n",
    "response = client.chat.completions.create(\n",
    "        model= \"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we entered content that was just a string of text, but we can also pass the model content that is not text with a compatible multimodal model, like 4o-mini. Let's pass the model [this image of the Eiffel Tower](https://upload.wikimedia.org/wikipedia/commons/thumb/8/85/Tour_Eiffel_Wikimedia_Commons_%28cropped%29.jpg/250px-Tour_Eiffel_Wikimedia_Commons_%28cropped%29.jpg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, the item in the image is located in Paris, France. It is the Eiffel Tower.\n"
     ]
    }
   ],
   "source": [
    "# Content can also be passed as a list of content parts, each with a defined type.\n",
    "new_message = {\"role\": \"user\",\n",
    "               \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Is the item in this image within that city?\"},\n",
    "                {\"type\": \"image_url\",  \"image_url\": {\"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/8/85/Tour_Eiffel_Wikimedia_Commons_%28cropped%29.jpg/500px-Tour_Eiffel_Wikimedia_Commons_%28cropped%29.jpg\"}}\n",
    "                ]\n",
    "                }\n",
    "\n",
    "messages.append(new_message)\n",
    "response = client.chat.completions.create(\n",
    "        model= \"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out [the chat completion docs](https://platform.openai.com/docs/api-reference/chat/create) to learn more about other parameters that can be specified in chats, some particularly useful ones are:\n",
    "- `temperature`: controls the randomness of the models output. Higher values make responses more creative and diverse, while lower values make them more focused and deterministic. Default: 1.\n",
    "- `max_completion_tokens`: sets the upper limit on the number of tokens the model can generate for a response, including visible text and internal reasoning. This helps manage response length and token costs. Default: None.\n",
    "- `response_format`: specifies the output format (e.g. {\"type\": \"json_object\"} ensures the output is valid JSON). Default: None.\n",
    "- `n`: how many responses the model generates for each input. Default: 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional References\n",
    "- [OpenAI Text Generation Guide](https://platform.openai.com/docs/guides/text-generation?lang=python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Prompting\n",
    "\n",
    "Thus far we have directly asked the model to do tasks, without any training or examples- this is often called *\"zero-shot prompting\"*. The generalization capabilities of LLMs allow zero-shot prompting to work successfully for a large and diverse number of tasks, however in some more complex cases the model can fall short. *\"Few-shot prompting\"* is a technique where you provide the examples in prompt to steer the model to better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back to our medication and condition dataset and try asking 4o-mini to solve this problem for us with zero-shot prompting through the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the medications for which the patient does not have an associated condition, we can compare the lists of medications and conditions for each patient.\n",
      "\n",
      "### Medications:\n",
      "- Patient 1: Metformin, Advil\n",
      "- Patient 2: Humira\n",
      "- Patient 3: Dupixent, Creatine\n",
      "\n",
      "### Conditions:\n",
      "- Patient 1: Diabetes, Chronic Asthma\n",
      "- Patient 2: Rheumatoid Arthritis\n",
      "- Patient 3: Eczema\n",
      "\n",
      "### Analysis:\n",
      "- **Patient 1**:\n",
      "  - Medications: Metformin, Advil\n",
      "  - Conditions: Diabetes, Chronic Asthma\n",
      "  - Both medications are associated with conditions.\n",
      "\n",
      "- **Patient 2**:\n",
      "  - Medications: Humira\n",
      "  - Conditions: Rheumatoid Arthritis\n",
      "  - Humira is associated with a condition.\n",
      "\n",
      "- **Patient 3**:\n",
      "  - Medications: Dupixent, Creatine\n",
      "  - Conditions: Eczema\n",
      "  - Dupixent is associated with a condition, but Creatine is not associated with any condition.\n",
      "\n",
      "### Result:\n",
      "The only medication without an associated condition is:\n",
      "- Patient 3: Creatine\n",
      "\n",
      "### Output:\n",
      "[('Patient 3', 'Creatine')]\n"
     ]
    }
   ],
   "source": [
    "cm_data = [\n",
    "    (\"Patient 1\", \"Metformin\"),\n",
    "    (\"Patient 1\", \"Advil\"),\n",
    "    (\"Patient 2\", \"Humira\"),\n",
    "    (\"Patient 3\", \"Dupixent\"),\n",
    "    (\"Patient 3\", \"Creatine\"),\n",
    "]\n",
    "\n",
    "mh_data = [\n",
    "    (\"Patient 1\", \"Diabetes\"),\n",
    "    (\"Patient 1\", \"Chronic Asthma\"),\n",
    "    (\"Patient 2\", \"Rheumatoid Arthritis\"),\n",
    "    (\"Patient 3\", \"Eczema\"),\n",
    "]\n",
    "content = f\"\"\"\n",
    "        Task: Go through the following medication and condition lists and return medications for which the patient does not have an associated condition.\n",
    "        \n",
    "        ## Input\n",
    "\n",
    "        Medications:\n",
    "        {cm_data}\n",
    "\n",
    "        Conditions:\n",
    "        {mh_data}\n",
    "\n",
    "        ## Output:\n",
    "        \"\"\"\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "        model= \"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": content}],\n",
    "        temperature=0,\n",
    "    )\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, this answer is pretty different than what we got with 4o-mini through ChatGPT earlier. That is probably due to the fact that ChatGPT has its own system prompt (see https://x.com/krishnanrohit/status/1755122786014724125) and may be updated more frequently than the API model.\n",
    "\n",
    "Regardless, the answer is excessively wordy and only identifies one of the two correct answers. Let's try to do *\"one-shot prompting\"* and give a single example to the model to see if it improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Patient 1', 'Advil'), ('Patient 3', 'Creatine')]\n"
     ]
    }
   ],
   "source": [
    "content = f\"\"\"\n",
    "        Task: Go through the following medication and condition lists and return medications for which the patient does not have an associated condition.\n",
    "\n",
    "        ## Example:\n",
    "        Medications:\n",
    "        [(\"Patient 1\", \"Atorvastatin\"), (\"Patient 2\", \"Methotrexate\"), (\"Patient 2\", \"Simvastatin\")]\n",
    "\n",
    "        Conditions:\n",
    "        [(\"Patient 1\", \"Hyperlipidemia\"), (\"Patient 2\", \"Psoriasis\")]\n",
    "\n",
    "        Expected Output:\n",
    "        [(\"Patient 2\", \"Simvastatin\")]\n",
    "\n",
    "        ## Input\n",
    "\n",
    "        Medications:\n",
    "        {cm_data}\n",
    "\n",
    "        Conditions:\n",
    "        {mh_data}\n",
    "\n",
    "        ## Output:\n",
    "        \"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "        model= \"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": content}],\n",
    "        temperature=0,\n",
    "    )\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! It is generally best practice to include at least one example in your prompt for any complex task. Some best practices for adding examples to your prompt are:\n",
    "- Use a clear and specific prompt format.\n",
    "- Use high quality and diverse examples (e.g. if you are asking for classification use positive and negative examples).\n",
    "- Iterate! See where zero-shot fails, then add examples iteratively based on failure modes.\n",
    "- There is some [research](https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf) to suggest using at least 2 examples, but that in-context learning may plateau after that.\n",
    "- Use tools to help you create and test prompts (e.g. Anthropic Workbench or Bedrock Prompt Management) or ask ChatGPT for help refining your prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beyond Few-Shot\n",
    "\n",
    "#### Files & Knowledge Bases\n",
    "Sometimes even quality examples can't get you all the way, and you might need to share additional knowledge with the model. In ChatGPT this is done through [File Uploads](https://help.openai.com/en/articles/8555545-file-uploads-faq) which allows you to upload up to 20 files (maximum size of 512 MB each) to be used for synthesis, transformation, or extraction.\n",
    "\n",
    "In the OpenAI API you can use the [Files API](https://platform.openai.com/docs/api-reference/files) to upload and use files in [Assistants](https://platform.openai.com/docs/api-reference/assistants), [Fine-tuning](https://platform.openai.com/docs/api-reference/fine-tuning), or Batch API. Support for files in Chat Completitions was recently added but only for [PDF files](https://platform.openai.com/docs/guides/pdf-files?api-mode=chat).\n",
    "\n",
    "Let's look at medical coding to the MedDRA dictionary and consider some other ways we could give the model extra knowledge outside of few-shot learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llt_code</th>\n",
       "      <th>llt_name</th>\n",
       "      <th>pt_code</th>\n",
       "      <th>llt_currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000001</td>\n",
       "      <td>Ventilation pneumonitis</td>\n",
       "      <td>10081988</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000002</td>\n",
       "      <td>11-beta-hydroxylase deficiency</td>\n",
       "      <td>10000002</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000003</td>\n",
       "      <td>11-oxysteroid activity incr</td>\n",
       "      <td>10033315</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000004</td>\n",
       "      <td>11-oxysteroid activity increased</td>\n",
       "      <td>10033315</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000005</td>\n",
       "      <td>17 ketosteroids urine</td>\n",
       "      <td>10000005</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   llt_code                          llt_name   pt_code llt_currency\n",
       "0  10000001           Ventilation pneumonitis  10081988            N\n",
       "1  10000002    11-beta-hydroxylase deficiency  10000002            Y\n",
       "2  10000003       11-oxysteroid activity incr  10033315            N\n",
       "3  10000004  11-oxysteroid activity increased  10033315            Y\n",
       "4  10000005             17 ketosteroids urine  10000005            Y"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import a small version (~30K/80K total codes) of the most recent MedDRA dictionary \n",
    "df = pd.read_csv(\"meddra_27_1_llt_small.txt\", sep=\" \", header=None, dtype=str)\n",
    "df.columns = [\"llt_code\", \"llt_name\", \"pt_code\", \"llt_currency\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llt_code</th>\n",
       "      <th>llt_name</th>\n",
       "      <th>pt_code</th>\n",
       "      <th>llt_currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7918</th>\n",
       "      <td>10008229</td>\n",
       "      <td>Cervical cancer</td>\n",
       "      <td>10008342</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7919</th>\n",
       "      <td>10008231</td>\n",
       "      <td>Cervical cancer recurrent</td>\n",
       "      <td>10008344</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7920</th>\n",
       "      <td>10008232</td>\n",
       "      <td>Cervical cancer stage 0</td>\n",
       "      <td>10061809</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7921</th>\n",
       "      <td>10008233</td>\n",
       "      <td>Cervical cancer stage I</td>\n",
       "      <td>10008345</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7922</th>\n",
       "      <td>10008234</td>\n",
       "      <td>Cervical cancer stage II</td>\n",
       "      <td>10008346</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7923</th>\n",
       "      <td>10008235</td>\n",
       "      <td>Cervical cancer stage III</td>\n",
       "      <td>10008347</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7924</th>\n",
       "      <td>10008236</td>\n",
       "      <td>Cervical cancer stage IV</td>\n",
       "      <td>10008348</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      llt_code                   llt_name   pt_code llt_currency\n",
       "7918  10008229            Cervical cancer  10008342            Y\n",
       "7919  10008231  Cervical cancer recurrent  10008344            Y\n",
       "7920  10008232    Cervical cancer stage 0  10061809            Y\n",
       "7921  10008233    Cervical cancer stage I  10008345            Y\n",
       "7922  10008234   Cervical cancer stage II  10008346            Y\n",
       "7923  10008235  Cervical cancer stage III  10008347            Y\n",
       "7924  10008236   Cervical cancer stage IV  10008348            Y"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try to get GPT to help us find the appropriate code for recurrent cervical cancer\n",
    "condition = \"recurrent cervical cancer\"\n",
    "df[df[\"llt_name\"].str.contains(\"cervical cancer\", case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The appropriate MedDRA LLT code for \"recurrent cervical cancer\" is \"10012400\".\n"
     ]
    }
   ],
   "source": [
    "system_message = (\"You are a skilled medical coder translating natural language medical history conditions and adverse events \"\n",
    "                  \"to codes from the MedDRA dictionary.\")\n",
    "input_message = f\"\"\"Determine the appropriate MedDRA LLT code for the following medical condition.\n",
    "                # Example:\n",
    "                ## Input: \"ventilation pneumonitis\"\n",
    "                ## Output: \"10000001\"\n",
    "                \n",
    "                # Input:\n",
    "                {condition}\n",
    "                \"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": input_message}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "        model= \"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llt_code</th>\n",
       "      <th>llt_name</th>\n",
       "      <th>pt_code</th>\n",
       "      <th>llt_currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11935</th>\n",
       "      <td>10012400</td>\n",
       "      <td>Depressive disorder, not elsewhere classified</td>\n",
       "      <td>10012378</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       llt_code                                       llt_name   pt_code  \\\n",
       "11935  10012400  Depressive disorder, not elsewhere classified  10012378   \n",
       "\n",
       "      llt_currency  \n",
       "11935            N  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check to see if that was correct\n",
    "output_code = \"10012400\"\n",
    "df[df[\"llt_code\"] == output_code]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the model is unable to code correctly, let's instead give the model the dictionary file as a source of knowledge and ask again. We could do this in ChatGPT with a file upload, or with the OpenAI API we can use the new [Responses API](https://platform.openai.com/docs/guides/responses-vs-chat-completions) with file search capabilities. \n",
    "\n",
    "The Responses API offers a new way to interact with OpenAI models, similar to Chat Completitions, but is built with agents in mind. This means it gives users access to tools that are common in agentic tasks like web search, file search, and computer use. The Responses API replaces OpenAI's previous agentic framework, called [Assistants](https://platform.openai.com/docs/assistants/overview) which will be deprecated in 2026. If you are new to the OpenAI platform, it is probably wise to start using Responses inplace of Chat Completitions as your API for interacting with OpenAI models. \n",
    "\n",
    "For our MedDRA problem let's use the file search tool in the Responses API, which enables models to retrieve information from a knowledge base of uploaded files. We begin by uploading a file to the Files API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic method to use for uploading files (from URL for file path) to Files API\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "def create_file(client, file_path):\n",
    "    if file_path.startswith(\"http://\") or file_path.startswith(\"https://\"):\n",
    "        # Download the file content from the URL\n",
    "        response = requests.get(file_path)\n",
    "        file_content = BytesIO(response.content)\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        file_tuple = (file_name, file_content)\n",
    "        result = client.files.create(\n",
    "            file=file_tuple,\n",
    "            purpose=\"assistants\"\n",
    "        )\n",
    "    else:\n",
    "        # Handle local file path\n",
    "        with open(file_path, \"rb\") as file_content:\n",
    "            result = client.files.create(\n",
    "                file=file_content,\n",
    "                purpose=\"assistants\"\n",
    "            )\n",
    "    print(result.id)\n",
    "    return result.id\n",
    "\n",
    "# Replace with your own file path or URL\n",
    "# file_id = create_file(client, \"meddra_27_1_llt_small.txt\")\n",
    "\n",
    "# To keep costs down the above line has been run once and we will all use the below file_id generated\n",
    "file_id = \"file-Bkod9mSgqMezv6E2eJNaeA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- The file_search tool uses the Vector Store object for storing and searching file content. Adding a file to a vector store automatically parses, chunks, embeds and stores the file in a vector database that's capable of both keyword and semantic search (more on this to come in the RAG section later). Each vector store can hold up to 10,000 files. \n",
    "\n",
    "For our simple example we will create a vector store, upload and add our file to the vector store, then give the vector store to the assistant. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreFile(id='file-Bkod9mSgqMezv6E2eJNaeA', created_at=1744585172, last_error=None, object='vector_store.file', status='in_progress', usage_bytes=0, vector_store_id='vs_67d9f5c8516c8191a000cd88e1284edb', attributes={}, chunking_strategy=StaticFileChunkingStrategyObject(static=StaticFileChunkingStrategy(chunk_overlap_tokens=400, max_chunk_size_tokens=800), type='static'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a vector store\n",
    "# vector_store = client.vector_stores.create(name=\"knowledge_base\")\n",
    "\n",
    "# To keep costs down the above line has been run once and we will all use the vector store generated\n",
    "vector_store_id = \"vs_67d9f5c8516c8191a000cd88e1284edb\"\n",
    " \n",
    "# Add a file to a vector store\n",
    "client.vector_stores.files.create(\n",
    "    vector_store_id=vector_store_id,\n",
    "    file_id=file_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(id='resp_67fc4335332c81918ad11e4c951ecaea0632bb47f11cd048', created_at=1744585525.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[ResponseFileSearchToolCall(id='fs_67fc43362e788191abab9295aba6d8180632bb47f11cd048', queries=['MedDRA LLT code for recurrent cervical cancer', 'recurrent cervical cancer', 'cervical cancer MedDRA LLT code'], status='completed', type='file_search_call', results=None), ResponseOutputMessage(id='msg_67fc43393868819185ecac37b96afe3d0632bb47f11cd048', content=[ResponseOutputText(annotations=[AnnotationFileCitation(file_id='file-Bkod9mSgqMezv6E2eJNaeA', index=67, type='file_citation', filename='meddra_27_1_llt_small.txt')], text='The MedDRA LLT code for \"recurrent cervical cancer\" is **10008344**.', type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FileSearchTool(type='file_search', vector_store_ids=['vs_67d9f5c8516c8191a000cd88e1284edb'], filters=None, max_num_results=20, ranking_options=RankingOptions(ranker='auto', score_threshold=0.0))], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None), status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=17618, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=78, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=17696), user=None, store=True)\n"
     ]
    }
   ],
   "source": [
    "content = f\"What is the MedDRA LLT code for the following medical condition: {condition}\"\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=content,\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_id]\n",
    "    }])\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the file search tool is called by the model, you will receive a response with multiple outputs:\n",
    "1. A file_search_call output item, which contains the id of the file search call.\n",
    "2. A message output item, which contains the response from the model, along with the file citations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MedDRA LLT code for \"recurrent cervical cancer\" is **10008344**.\n"
     ]
    }
   ],
   "source": [
    "# The first text response from the model\n",
    "print(response.output[1].content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llt_code</th>\n",
       "      <th>llt_name</th>\n",
       "      <th>pt_code</th>\n",
       "      <th>llt_currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8029</th>\n",
       "      <td>10008344</td>\n",
       "      <td>Cervix carcinoma recurrent</td>\n",
       "      <td>10008344</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      llt_code                    llt_name   pt_code llt_currency\n",
       "8029  10008344  Cervix carcinoma recurrent  10008344            Y"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check to see if that was correct\n",
    "output_code = \"10008344\"\n",
    "df[df[\"llt_code\"] == output_code]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using file search in Responses API is a great precursor to understanding Retrieval-Augmented Generation (RAG) systems, a topic which will be covered in a later module. By integrating file search, you are storing information from files in a vector store which can then be used to dynamically retrieve relevant information and feed that context to the model. This approach allows the LLM to augment its responses with factual data stored externally.\n",
    "\n",
    "Like with other RAG systems, you can fine-tune some parameters to optimize search precision and relevance. For example, you can customize the number of results retrieved from the vector store, and add metadata filtering to enhance the quality of retrieved content. To explore these concepts further check out the [OpenAI File Search Guide](https://platform.openai.com/docs/guides/tools-file-search#retrieval-customization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finetuning\n",
    "Sometimes just passing a file or knowledge base to the model may not be sufficient, and in *some* of these cases fine-tuning can help. Fine-tuning is the process of adapting an existing model to perform better for a specific task by training it on a task-specific dataset. This process requires a large, well-structured dataset and usually a **significant amount of time, effort, and cost**. It is always recommended to first explore prompt engineering, integrating knowledge bases, and/or leveraging function calling to achieve desired results before considering fine-tuning.\n",
    "\n",
    "Some common use cases where fine-tuning can improve results: \n",
    "- Handling many edge cases in specific ways\n",
    "- Setting the style, tone, format, or other qualatative aspects in ways that's hard to articulate in a prompt\n",
    "- Improving reliability at producing a desired output\n",
    "\n",
    "For some long-term projects using LLMs, fine-tuning can reduce cost and/or latency associated with repeatedly sending lengthy prompts. In these cases the upfront cost of fine-tuning and hosting a fine-tuned model can pay off over time. An increasingly common trend is to replace usage of larger LLMs (like gpt-4o) with a fine-tuned smaller model (like gpt-4o-mini) to achieve cost savings and maintain or improve performance.\n",
    "\n",
    "Returning to our medical coding example we can consider how companies often accumulate large datasets of historical coding decisions. These datasets often contain the most challenging cases for medical coding (e.g. where conditions are represented differently than in the dictionary and may contain abbreviations and/or specialized terminology). In this context, it might be useful to fine-tune a smaller model with the historical coding dataset to create a company-specific medical coding model that makes decisions similar to past coding decisions.\n",
    "\n",
    "Because most of us are using LLMs for proof-of-concept and shorter-term projects, we won't cover the specifics of fine-tuning with the OpenAI API here, but refer to the [OpenAI fine-tuning docs](https://platform.openai.com/docs/guides/fine-tuning) to learn more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
