{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Building a Retrieval-Augmented Generation (RAG) System for Biotechnology Applications**\n",
    "\n",
    "This notebook presents a comprehensive guide to building a Retrieval-Augmented Generation (RAG) system tailored for biotechnology applications. Leveraging advanced information retrieval and generative modeling techniques, the system efficiently navigates and synthesizes vast amounts of scientific data to provide insightful and accurate responses to domain-specific queries.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 3px solid white; width: 100%;\">\n",
    "<hr style=\"border: 3px solid white; width: 100%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## **Motivation & Background** <a id=\"motivatio-&-background\"></a>\n",
    "\n",
    "\n",
    "Large language models (LLMs) have achieved remarkable success, though they still face significant limitations, especially in domain-specific or knowledge-intensive tasks. These limitations often manifest as **hallucinations** —answers that sound plausible but are factually incorrect—when handling queries beyond the model’s training data or requiring current information.\n",
    "\n",
    "To address these challenges, **Retrieval-Augmented Generation (RAG)** incorporates external knowledge sources. By retrieving relevant document chunks through semantic similarity, RAG mitigates factual inaccuracies and keeps responses up to date. This integration ensures LLMs have the context they need to remain both accurate and current, fostering widespread adoption of RAG in real-world applications.\n",
    "\n",
    "### Why Use RAG?\n",
    "\n",
    "1. **Access to Fresh Information**  \n",
    "   LLMs rely on static training corpora, risking outdated responses. RAG taps into external, dynamic databases—providing the latest facts and cutting-edge data.  \n",
    "\n",
    "2. **Factual Grounding**  \n",
    "   LLMs excel at generating fluent text but can falter on factual correctness. By feeding retrieved text directly into the prompt, RAG reduces hallucinations and ensures evidence-based answers.\n",
    "\n",
    "3. **Scalability & Efficiency**  \n",
    "   Even with long context windows, LLMs have token limits. RAG’s retrieval stage selectively brings in only the most relevant chunks, which saves costs and tokens while boosting relevance.\n",
    "\n",
    "4. **Semantic Search & Re-Rankers**  \n",
    "   Modern RAG systems often leverage vector databases (for semantic search), possible keyword-based fallback, and re-rankers that ensure the top results are truly on-topic.\n",
    "\n",
    "5. **Quality & Reliability**  \n",
    "   By anchoring generated content to curated knowledge, RAG helps maintain consistency and accuracy. This is essential for domains like biotechnology, finance, or medicine, where mistakes can have serious consequences.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 3px solid white; width: 100%;\">\n",
    "<hr style=\"border: 3px solid white; width: 100%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Retrieval-Augmented Generation (RAG) <a id=\"introduction-to-rag\"></a>\n",
    "\n",
    "## What is RAG? <a id=\"what-is-rag\"></a>\n",
    "\n",
    "**Retrieval-Augmented Generation (RAG)** is an advanced AI framework that integrates **information retrieval** with **generative models** to produce more accurate and contextually relevant responses. Unlike traditional generative models that rely solely on learned parameters, RAG actively retrieves relevant information from external datasets, **enhancing responses with up-to-date and domain-specific knowledge**.\n",
    "\n",
    "## Core Components <a id=\"core-components\"></a>\n",
    "\n",
    "### **Indexing**\n",
    "- Load and preprocess documents  \n",
    "- Split text into **manageable chunks**  \n",
    "- Generate **vector embeddings**  \n",
    "- Store vectors efficiently in **databases**  \n",
    "\n",
    "### **Retriever**\n",
    "- Transform queries into **embeddings**  \n",
    "- Perform **semantic similarity search**  \n",
    "- Retrieve **relevant documents**  \n",
    "- Apply **optional ranking and filtering**  \n",
    "\n",
    "### **Generator**\n",
    "- **Prompt engineering** for query handling  \n",
    "- **Context integration** with retrieved documents  \n",
    "- Generate responses using **LLMs**  \n",
    "- **Refine and format** outputs  \n",
    "\n",
    "## Use Cases and Advantages <a id=\"use-cases-and-advantages\"></a>\n",
    "\n",
    "- **Improved Accuracy**: RAG reduces hallucinations by incorporating real-world data.  \n",
    "- **Domain-Specific Applications**: Ideal for fields requiring precise and current knowledge, such as **biotechnology**.  \n",
    "- **Enhanced Interactive Systems**: Strengthens chatbots and virtual assistants with **context-aware responses**.  \n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 3px solid white; width: 100%;\">\n",
    "<hr style=\"border: 3px solid white; width: 100%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RAG Architectural Diagram** <a id=\"architectural-diagram\"></a>\n",
    "\n",
    "\n",
    "![RAG Paradigm](rag_paradigm.png)\n",
    "\n",
    "*Figure 1: Overview of the Retrieval-Augmented Generation System Architecture*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 3px solid white; width: 100%;\">\n",
    "<hr style=\"border: 3px solid white; width: 100%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **Practical Implementation** <a id=\"practical-implementation\"></a>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook demonstrates how to build a **Retrieval-Augmented Generation (RAG) system** tailored for biotechnology applications.\n",
    "\n",
    "### Key Steps:\n",
    "- Load and process a small subset of **PubMed** data.\n",
    "- Convert data into **LangChain Document** objects.\n",
    "- Split documents into **manageable chunks** for semantic retrieval.\n",
    "- Build a **vector index** using **Chroma** with domain-specific embeddings.\n",
    "- Construct a **Retrieval-Augmented Generation** (RAG) chain powered by **ChatGPT**.\n",
    "- Run example queries and display results.\n",
    "\n",
    "**Note:** For production use, ensure secure management of **environment variables** and **API keys**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ------------------------------\n",
    "# Environment Setup: API Key and Model Name\n",
    "# ------------------------------\n",
    "# In this example, we set the OpenAI API key for ChatGPT-based generation.\n",
    "# For production, load the key securely (e.g., from environment variables or a config file).\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"_\"  # Replace \"_\" with your actual OpenAI API key if needed.\n",
    "# Ensure the API key is set; otherwise, raise a warning.\n",
    "if os.environ.get(\"OPENAI_API_KEY\") is None or os.environ.get(\"OPENAI_API_KEY\") == \"_\":\n",
    "    print(\"Warning: OPENAI_API_KEY is not set securely. Please configure it properly for production use.\")\n",
    "\n",
    "# Set the model name used for chat generation.\n",
    "# You can switch models based on your requirements.\n",
    "model_name = \"gpt-4o-mini\"  \n",
    "# Alternative model example (commented out):\n",
    "# model_name = \"o3-mini-2025-01-31\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preprocessing and Indexing** <a id=\"data-preprocessing-and-indexing\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Idexing Paradigm](indexing.jpeg)\n",
    "\n",
    "*Figure 2: Indexing Process*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1199 documents from PubMed.\n"
     ]
    }
   ],
   "source": [
    "# Import LangChain components for handling documents, text splitting, and chain construction.\n",
    "from langchain.schema import Document\n",
    "import json\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "#\n",
    "# This section converts raw data (PubMed abstracts) into LangChain Document objects,\n",
    "# which are easier to process for embedding and retrieval.\n",
    "#\n",
    "# The load_dataset function fetches a subset of PubMed articles from the \"scientific_papers\" dataset.\n",
    "# from datasets import load_dataset \n",
    "# pubmed_data = load_dataset('scientific_papers', 'pubmed', split='train[:1%]', trust_remote_code=True)\n",
    "#\n",
    "# To save time during demonstrations, we have pre-saved the abstracts from this subset read them in below.\n",
    "with open(\"pubmed_abstracts.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    pubmed_data = json.load(f)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Converting the dataset to LangChain Document objects.\n",
    "# We use only the 'abstract' field for demonstration. If an item has an abstract, it is converted into a Document.\n",
    "# The Document objects include page_content (the abstract) and optional metadata.\n",
    "# ------------------------------\n",
    "documents = []\n",
    "for item in pubmed_data:\n",
    "    documents.append(Document(page_content=item))\n",
    "print(f\"Loaded {len(documents)} documents from PubMed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ------------------------------\n",
    "## **Splitting Documents into Chunks**\n",
    " ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks after splitting: 2189\n"
     ]
    }
   ],
   "source": [
    "# For better retrieval and to respect model token limits, we split longer texts into smaller chunks.\n",
    "#\n",
    "# RecursiveCharacterTextSplitter is used here to chunk documents.\n",
    "#   • chunk_size: The maximum size of each chunk (e.g., 1000 characters).\n",
    "#   • chunk_overlap: The number of characters of overlap between consecutive chunks for better context retention.\n",
    "#\n",
    "# Chunking improves retrieval granularity and helps the underlying LLM to process context effectively.\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,   # Set chunk size according to your data/model limits\n",
    "    chunk_overlap=200  # Small overlap to ensure context continuity in retrieval\n",
    ")\n",
    "docs_split = splitter.split_documents(documents)\n",
    "print(f\"Number of chunks after splitting: {len(docs_split)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "## **Building the Embedding and Vector Store (Indexing)**\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/40/1jrc6q0d1kl4zvglx9dr2vym0000gn/T/ipykernel_1497/3135498108.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# We use OpenAI for general embeddings, but domain-specific embeddings (for biomedical text) may perform better.\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# Create the Chroma vector store using the split document chunks. \n",
    "# Chroma handles embedding computation and efficient storage/retrieval.\n",
    "# The collection_name \"pubmed_biotech\" organizes the stored vectors.\n",
    "vectorstore = Chroma.from_documents(\n",
    "    docs_split,\n",
    "    embedding_model,\n",
    "    collection_name=\"pubmed_biotech\"\n",
    ")\n",
    "\n",
    "# Create a retriever from the vector store.\n",
    "# search_kwargs such as k=5 ensure that we retrieve the top 5 most relevant chunks for a given query.\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Retrieval and Generation Paradigm](prompt-and-generation.jpeg)\n",
    "\n",
    "*Figure 2: Retrieval and Generation Paradigm*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "### **Building the Retrieval-Augmented Generation (RAG) Chain with ChatOpenAI**\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/40/1jrc6q0d1kl4zvglx9dr2vym0000gn/T/ipykernel_1497/1709382271.py:9: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm_chatgpt = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "# Now, we switch to the generative component that uses ChatGPT for answer generation.\n",
    "#\n",
    "# The ChatOpenAI component creates an instance of the chat-model.\n",
    "# Here, we use a model (gpt-4o-mini or another specified) with temperature=0 for focused, deterministic responses.\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm_chatgpt = ChatOpenAI(\n",
    "    model_name=model_name,                 # Model name as defined earlier\n",
    "    temperature=0,                         # Temperature 0 for precise answers in domain-specific questions\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\")  # Use the API key from the environment\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "## **Define a prompt template for the RAG chain.**\n",
    "### The template instructs the LLM to use the provided context and answer the question.\n",
    "### It also instructs the model to state if the context is insufficient.\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Use the following context to answer the question. \n",
    "If the context is insufficient, just say so.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----------------------\n",
    "## **Build the RetrievalQA Chain**\n",
    "\n",
    "### The `chain_type=\"stuff\"` combines all retrieved document chunks into the prompt.  \n",
    "### Other chain types (e.g., `map_reduce`, `refine`) can also be explored.\n",
    "\n",
    "### This chain utilizes the previously defined LLM and retriever.\n",
    "### It first retrieves relevant document chunks from the vector store and then passes them, along with the user query, to the chat-based LLM to generate an answer.\n",
    "\n",
    "----------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm_chatgpt,\n",
    "    chain_type=\"stuff\",   # This chain type simply concatenates the retrieved documents for the LLM prompt.\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")\n",
    "\n",
    "\n",
    "# Define a convenience function to run queries on the RAG system.\n",
    "#\n",
    "# This function takes a text query, passes it to the RAG chain, and returns the answer.\n",
    "def query_rag_system(query: str) -> str:\n",
    "    \"\"\"Uses ChatGPT for generation with retrieved context. Returns the generated answer.\"\"\"\n",
    "    answer = rag_chain.run(query)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/40/1jrc6q0d1kl4zvglx9dr2vym0000gn/T/ipykernel_1497/548986264.py:3: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  answer_1 = rag_chain.run(question_1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Summarize the latest CRISPR gene editing findings from these abstracts.\n",
      "A: The latest findings on CRISPR gene editing highlight several key advancements and challenges. The CRISPR/Cas9 system is recognized for its precision, efficiency, versatility, and ease of use, facilitating both basic research and applied crop improvement. Recent applications have successfully extended CRISPR/Cas9 technology to biallelic mutations in woody perennials, such as Populus. However, challenges remain, particularly in outcrossing species where sequence polymorphisms can hinder the effectiveness of CRISPR/Cas9. Research has demonstrated the system's sensitivity to allelic heterozygosity and has proposed tools and strategies to address these issues. Additionally, the study of CRISPR-Cas systems in bacteria and archaea has enhanced our understanding of virus defense mechanisms, although the ecological role of these systems in nature is still complex and underexplored. Overall, the advancements in CRISPR technology continue to evolve, with ongoing research aimed at overcoming existing obstacles and expanding its applications.\n",
      "\n",
      "Q: Discuss current advancements in immunotherapy for lung cancer.\n",
      "A: The provided context does not contain specific information about current advancements in immunotherapy for lung cancer. It primarily discusses the role of epidermal growth factor receptor (EGFR) mutations in therapeutic decision-making for non-small cell lung cancer (NSCLC), the use of cytologic fine-needle aspirates for diagnosis and molecular information, and mentions treatments like gefitinib, erlotinib, and bevacizumab. However, it does not address immunotherapy advancements specifically. Therefore, the context is insufficient to answer the question about current advancements in immunotherapy for lung cancer.\n"
     ]
    }
   ],
   "source": [
    "# Example biotech question\n",
    "question_1 = \"Summarize the latest CRISPR gene editing findings from these abstracts.\"\n",
    "answer_1 = rag_chain.run(question_1)\n",
    "print(f\"Q: {question_1}\\nA: {answer_1}\\n\")\n",
    "\n",
    "question_2 = \"Discuss current advancements in immunotherapy for lung cancer.\"\n",
    "answer_2 = rag_chain.run(question_2)\n",
    "print(f\"Q: {question_2}\\nA: {answer_2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Display**\n",
    "### Function to display Q&A results in an easy-to-read format.\n",
    "### This is especially useful in a notebook setting to provide visual emphasis using increased font sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def display_qna(question, answer, q_font_size=18, a_font_size=16):\n",
    "    \"\"\"\n",
    "    Displays the question and answer with increased font sizes.\n",
    "    \"\"\"\n",
    "    html_content = f\"\"\"\n",
    "    <div st\n",
    "    yle=\"margin-bottom: 20px;\">\n",
    "        <p style=\"font-size:{q_font_size}px; font-weight: bold; color: #2E86C1;\">Question:</p>\n",
    "        <p style=\"font-size:{q_font_size}px; font-weight: bold; color: #2E86C1;\">{question}</p>\n",
    "        <p style=\"font-size:{a_font_size}px; margin-top: 10px;\"><strong>Answer:</strong> {answer}</p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(html_content))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Example Queries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div st\n",
       "    yle=\"margin-bottom: 20px;\">\n",
       "        <p style=\"font-size:18px; font-weight: bold; color: #2E86C1;\">Question:</p>\n",
       "        <p style=\"font-size:18px; font-weight: bold; color: #2E86C1;\">Summarize recent findings on CRISPR gene editing.</p>\n",
       "        <p style=\"font-size:16px; margin-top: 10px;\"><strong>Answer:</strong> Recent findings on CRISPR gene editing highlight its precision, efficiency, versatility, and ease of adoption, making it a significant breakthrough in genome editing. The CRISPR/Cas9 system has been successfully applied to create biallelic mutations in stably transformed Populus, extending its use to woody perennials. However, challenges remain, particularly in outcrossing species where sequence polymorphisms can hinder the effectiveness of CRISPR/Cas9. Research has demonstrated the system's sensitivity to allelic heterozygosity and has proposed tools and strategies to address these issues. Additionally, CRISPR technology offers a more definitive approach than previous methods for understanding functional redundancy in plant genomes. Overall, the advancements in CRISPR/Cas9 are expected to accelerate both basic research and applied crop improvement.</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div st\n",
       "    yle=\"margin-bottom: 20px;\">\n",
       "        <p style=\"font-size:18px; font-weight: bold; color: #2E86C1;\">Question:</p>\n",
       "        <p style=\"font-size:18px; font-weight: bold; color: #2E86C1;\">What are the latest advancements in immunotherapy for cancer?</p>\n",
       "        <p style=\"font-size:16px; margin-top: 10px;\"><strong>Answer:</strong> The context provided mentions several advancements in immunotherapy for cancer, particularly focusing on colorectal cancer. Key points include:\n",
       "\n",
       "1. **Cytokine-Induced Killer (CIK) Cells**: CIK cell therapy has shown favorable responses in treating colorectal cancer without significant toxicities, making it a promising therapeutic strategy for patients with metastatic colorectal cancer.\n",
       "\n",
       "2. **Dendritic Cell Vaccines and T Cell Therapy**: Previous clinical studies have demonstrated promising results for metastatic colorectal cancer using cell-based immunotherapy approaches like dendritic cell vaccines and sentinel lymph node T cell therapy.\n",
       "\n",
       "3. **Combination Therapies**: Advances in combination chemotherapy regimens have improved progression-free and overall survival rates for colorectal cancer patients, although conventional therapies still have significant toxicity.\n",
       "\n",
       "4. **Research on Toll-Like Receptors (TLRs)**: In breast cancer, TLRs are being explored as important targets for treatment due to their role in inflammation and cancer progression.\n",
       "\n",
       "Overall, the advancements highlight the potential of cell-based immunotherapies and the exploration of immune system components like TLRs in cancer treatment. However, the context does not provide a comprehensive overview of all the latest advancements in immunotherapy across different cancer types.</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div st\n",
       "    yle=\"margin-bottom: 20px;\">\n",
       "        <p style=\"font-size:18px; font-weight: bold; color: #2E86C1;\">Question:</p>\n",
       "        <p style=\"font-size:18px; font-weight: bold; color: #2E86C1;\">What are the latest EGFR mutation lung cancer therapies?</p>\n",
       "        <p style=\"font-size:16px; margin-top: 10px;\"><strong>Answer:</strong> The latest therapies for lung cancer associated with EGFR mutations include the use of epidermal growth factor receptor tyrosine kinase inhibitors (EGFR-TKIs) such as gefitinib and erlotinib. These treatments have shown improved survival rates in non-small cell lung cancer (NSCLC) patients with EGFR mutations compared to those without the mutation. Additionally, the development of specific antibodies against EGFR mutation proteins is being explored for diagnosis and treatment. There is also ongoing research into the use of bevacizumab, an anti-VEGF monoclonal antibody, in combination with chemotherapy or erlotinib for advanced non-squamous NSCLC patients, although its efficacy and safety in patients with active brain metastases remain unknown.</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query1 = \"Summarize recent findings on CRISPR gene editing.\"\n",
    "answer1 = query_rag_system(query1)\n",
    "display_qna(query1, answer1)\n",
    "\n",
    "query2 = \"What are the latest advancements in immunotherapy for cancer?\"\n",
    "answer2 = query_rag_system(query2)\n",
    "display_qna(query2, answer2)\n",
    "\n",
    "query3 = \"What are the latest EGFR mutation lung cancer therapies?\"\n",
    "answer3 = query_rag_system(query3)\n",
    "display_qna(query3, answer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dynamic Index Updating**\n",
    "\n",
    "The RAG system leverages publicly available scientific abstracts from [PubMed](https://pubmed.ncbi.nlm.nih.gov/) to retrieve and generate insightful responses. This could be extended to multiple datasets to enrich the RAG system's functionality. Extending to multiple datasets (e.g. [BioRxiv](https://www.biorxiv.org/)) involves similar steps: loading, embedding, and indexing. \n",
    "\n",
    "Below we merge embeddings from two new documents into the existing Chroma vector store.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added new documents to the vectorstore!\n"
     ]
    }
   ],
   "source": [
    "new_documents = [\n",
    "    \"New Abstract 1: Adenosine-to-inosine (A-to-I) editing of double-stranded RNA (dsRNA) by ADAR1 is an essential modifier of the immunogenicity of cellular dsRNA. The role of MDA5 in sensing unedited cellular dsRNA and the downstream activation of type I interferon (IFN) signaling are well established. However, we have an incomplete understanding of pathways that modify the response to unedited dsRNA. We performed a genome-wide CRISPR screen and showed that GGNBP2, CNOT10, and CNOT11 interact and regulate sensing of unedited cellular dsRNA. We found that GGNBP2 acts between dsRNA transcription and its cytoplasmic sensing by MDA5. GGNBP2 loss prevented induction of type I IFN and autoinflammation after the loss of ADAR1 editing activity by modifying the subcellular distribution of endogenous A-to-I editing substrates and reducing cytoplasmic dsRNA load. These findings reveal previously undescribed pathways to modify diseases associated with ADAR mutations and may be determinants of response or resistance to small-molecule ADAR1 inhibitors.\",\n",
    "    \"New Abstract 2: T cell immunoglobulin and mucin domain-containing protein 3 (TIM-3) is an important immune checkpoint molecule initially identified as a marker of IFN-γ–producing CD4+ and CD8+ T cells. Since then, our understanding of its role in immune responses has significantly expanded. Here, we review emerging evidence demonstrating unexpected roles for TIM-3 as a key regulator of myeloid cell function, in addition to recent work establishing TIM-3 as a delineator of terminal T cell exhaustion, thereby positioning TIM-3 at the interface between fatigued immune responses and reinvigoration. We share our perspective on the antagonism between TIM-3 and T cell stemness, discussing both cell-intrinsic and cell-extrinsic mechanisms underlying this relationship. Looking forward, we discuss approaches to decipher the underlying mechanisms by which TIM-3 regulates stemness, which has remarkable potential for the treatment of cancer, autoimmunity, and autoinflammation.\"\n",
    "]\n",
    "\n",
    "\n",
    "# 1) Convert raw strings into LangChain Document objects\n",
    "new_docs = [Document(page_content=text) for text in new_documents]\n",
    "\n",
    "# 2) Split the new documents for chunking (helps with retrieval accuracy)\n",
    "split_new_docs = splitter.split_documents(new_docs)\n",
    "\n",
    "# 3) Add these chunks to your vectorstore\n",
    "#    (This automatically handles embeddings and indexing behind the scenes.)\n",
    "vectorstore.add_documents(split_new_docs)\n",
    "\n",
    "# 4) Confirm the addition in a way specific to your vectorstore\n",
    "#    e.g., check how many docs are in the store\n",
    "print(\"Successfully added new documents to the vectorstore!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div st\n",
       "    yle=\"margin-bottom: 20px;\">\n",
       "        <p style=\"font-size:18px; font-weight: bold; color: #2E86C1;\">Question:</p>\n",
       "        <p style=\"font-size:18px; font-weight: bold; color: #2E86C1;\">What are the roles of GGNBP2, CNOT10, and CNOT11 in regulating the sensing of unedited cellular dsRNA?</p>\n",
       "        <p style=\"font-size:16px; margin-top: 10px;\"><strong>Answer:</strong> GGNBP2, CNOT10, and CNOT11 interact and regulate the sensing of unedited cellular dsRNA. Specifically, GGNBP2 acts between the transcription of dsRNA and its cytoplasmic sensing by MDA5. The loss of GGNBP2 prevents the induction of type I interferon (IFN) and autoinflammation that typically occurs when ADAR1 editing activity is lost. This is achieved by modifying the subcellular distribution of endogenous A-to-I editing substrates and reducing the cytoplasmic load of dsRNA. The roles of CNOT10 and CNOT11 in this context are not explicitly detailed in the provided context, but they are part of the regulatory pathway alongside GGNBP2.</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div st\n",
       "    yle=\"margin-bottom: 20px;\">\n",
       "        <p style=\"font-size:18px; font-weight: bold; color: #2E86C1;\">Question:</p>\n",
       "        <p style=\"font-size:18px; font-weight: bold; color: #2E86C1;\">How does TIM-3 regulate myeloid cell activity and T cell exhaustion in immune responses?</p>\n",
       "        <p style=\"font-size:16px; margin-top: 10px;\"><strong>Answer:</strong> The context provides information that TIM-3 is a key regulator of myeloid cell function and is involved in delineating terminal T cell exhaustion. It suggests that TIM-3 plays a role at the interface between fatigued immune responses and the potential for reinvigoration of T cells. Specifically, TIM-3 is implicated in the regulation of T cell stemness, which may influence the ability of T cells to respond effectively to immune challenges. The context indicates that understanding the mechanisms by which TIM-3 regulates these processes could have significant implications for treating conditions such as cancer, autoimmunity, and autoinflammation. However, the specific mechanisms of how TIM-3 regulates myeloid cell activity and T cell exhaustion are not detailed in the provided context.</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_query1 = \"What are the roles of GGNBP2, CNOT10, and CNOT11 in regulating the sensing of unedited cellular dsRNA?\"\n",
    "new_answer1 = query_rag_system(new_query1)\n",
    "display_qna(new_query1, new_answer1)\n",
    "new_query2 = \"How does TIM-3 regulate myeloid cell activity and T cell exhaustion in immune responses?\"\n",
    "new_answer2 = query_rag_system(new_query2)\n",
    "\n",
    "display_qna(new_query2,new_answer2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 3px solid white; width: 100%;\">\n",
    "<hr style=\"border: 3px solid white; width: 100%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Expert-Level Insights** <a id=\"expert-level-insights\"></a>\n",
    "\n",
    "###  **Challenges and Mitigation Strategies** <a id=\"challenges-and-mitigation-strategies\"></a>\n",
    "\n",
    "Building a robust RAG system involves navigating several challenges. Below are common issues and strategies to mitigate them:\n",
    "\n",
    "- **Retrieval Accuracy**:\n",
    "    - *Challenge*: Irrelevant documents may be retrieved.\n",
    "    - *Mitigation*: Use advanced embedding models and increase the quality of your dataset. Fine-tune the embedding model on domain-specific data to enhance relevance.\n",
    "    \n",
    "- **Hallucination in Generation**:\n",
    "    - *Challenge*: The generative model may produce incorrect or nonsensical answers.\n",
    "    - *Mitigation*: Fine-tune the generative model on domain-specific datasets and implement constraints during generation, such as length limits or specific tokens.\n",
    "    \n",
    "- **Scalability**:\n",
    "    - *Challenge*: Handling large datasets efficiently.\n",
    "    - *Mitigation*: Utilize optimized indexing techniques like FAISS's hierarchical navigable small world graphs (HNSW) for faster searches. Distribute the index across multiple machines if necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 3px solid white; width: 100%;\">\n",
    "<hr style=\"border: 3px solid white; width: 100%;\">\n",
    "\n",
    "## **Conclusion** <a id=\"conclusion\"></a>\n",
    "\n",
    "In this tutorial, we've built a **Retrieval-Augmented Generation (RAG)** system tailored for the **biotechnology** and **biomedical research** industries. By integrating advanced retrieval mechanisms with powerful generative models, we've created a tool capable of navigating complex scientific data and providing insightful, evidence-based answers to domain-specific queries. This system showcases the potential of RAG in transforming how professionals interact with vast datasets, ultimately accelerating research and innovation in biotechnology and biomedical fields.\n",
    "\n",
    "### **Key Takeaways:**\n",
    "\n",
    "- #### **Chroma Vector Store:**\n",
    "  - We generated vector embeddings using OpenAI's embedding model and built a Chroma vector store.\n",
    "  - Employed **Chroma** for efficient similarity searches and vector storage within large datasets.\n",
    "  - Leveraged Chroma's capabilities to handle scalability and optimize performance for biomedical data.\n",
    "\n",
    "- #### **Generative Models:**\n",
    "  - Leveraged OpenAI models (4o-mini) for generating coherent and contextually relevant responses based on retrieved documents.\n",
    "  - Integrated the RAG chain architecture to mitigate hallucinations, ensuring that large language model (LLM) outputs remain evidence-based.\n",
    "\n",
    "- #### **Optimization:**\n",
    "  - Implemented chunking (splitting documents) to overcome token length limitations and ensure context continuity.\n",
    "\n",
    "- #### **Persistence:**\n",
    "  - Enabled saving and loading of Chroma vector stores and document lists to streamline future operations and support system scalability.\n",
    "\n",
    "### **Potential Next Steps:**\n",
    "\n",
    "- #### **Fine-Tuning Models:**\n",
    "  - Further enhance the system by fine-tuning the generative model on specialized biotechnology and biomedical datasets to improve domain-specific performance.\n",
    "\n",
    "- #### **Scalability:**\n",
    "  - Explore more advanced Chroma indexing techniques and alternative chain types to handle larger datasets and complex retrieval parameters.\n",
    "\n",
    "- #### **Deployment:**\n",
    "  - Consider deploying the RAG system as an API or integrating it into applications for real-time information retrieval and generation.\n",
    "  - Implement persistence strategies, such as saving/loading the vector store, to support scaling up the system for broader use cases.\n",
    "\n",
    "By following these next steps, you can continue to refine and expand the capabilities of your RAG system, ensuring it remains a valuable tool for advancing research and innovation in the biotechnology and biomedical research sectors.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
